# Специфікація проекту: Інтеграція Autonomous LLM Provider MCP

## 1. Коротке РЕЗЮМЕ (Executive Summary)
Створення автономного агента (на ім'я Клим) на базі `llm-provider-mcp`. Цей сервіс буде асинхронно виконувати важкі задачі (наприклад, аналіз великих масивів логів, глибока діагностика графа), підключаючись як клієнт до основного `grynya-mcp-server`. Це розвантажить основний контекст взаємодії Грині.

## 2. Опис Проблеми
Основний агент (Гриня) обмежений вікном контексту та часом очікування синхронних інструментів. При обробці великих масивів даних або довгих циклів це призводить до залипань (та утруднює паралельну роботу). Нам потрібен виділений агент (Клим), якому можна делегувати такі задачі.

## 3. Критерії Успіху
- Гриня успішно підключається до серверної частини Клима (`llm-provider-mcp`) та може безперешкодно передавати йому цільові команди через MCP-інструменти.
- Клим (`llm-provider-mcp`) зі свого боку успішно підключається до `grynya-mcp-server` через підхід SSE як клієнт.
- Інструмент для запуску задач не блокує основний потік (реалізовано асинхронне виконання).
- Є можливість перевіряти статус виконання та читати лог-виводи кожної конкретної задачі.
- Базовий proof-of-concept (PoC) дозволяє запустити задачу і отримати від Клима звіт: "Бачу базу та інструменти, полет нормальний".

## 4. Портрети Користувачів (User Personas)
- **Гриня (Системний Агент):** Виступає оркестратором. Відправляє задачі Климу та періодично перевіряє їх результати або логи, продовжуючи нормальну комунікацію з користувачем.
- **Клим (Автономний Воркер):** Асинхронно виконує доручені Гринею завдання, користуючись інструментами `grynya-mcp-server`.

## 5. Шлях Користувача (User Journey Flow)
1. Гриня викликає інструмент `start_async_agent_task` на `llm-provider-mcp` (кличе Клима).
2. Інструмент за долі секунди повертає `task_id` і статус (напр., "Task Started") без блокування.
3. У фоні Клим підключається до `grynya-mcp-server` по SSE, ініціює сесію як клієнт, отримує інструменти і виконує генерацію для вирішення задачі, ведучи системний лог дій.
4. Гриня може продовжувати спілкування з користувачем без жодних затримок.
5. За потреби, Гриня використовує інструмент `check_task_status(task_id)`, щоб подивитися, на якому етапі знаходиться Клим, або переглянути логи та результат виконання.

## 6. Функціональні Вимоги
### Обов'язково зробити (P0 - Must Have)
- **Асинхронний запуск задач:** Механізм запуску задач через `asyncio.create_task` у FastMCP-сервері Клима, без блокування головного event loop'у обробки запитів.
- **Трекінг статусу та логів:** Інструмент для моніторингу задач (`check_task_status`). Повинен відображати статус (pending, running, completed, error), результат та повні текстові логи задачі (stdout/stderr процесу LLM та клієнта).
- **Базовий PoC Клієнта:** Задача, в якій Клим рапортує, що підключився до інструментів успішно і готовий працювати як автономний агент.

### Бажано зробити (P1 - Should Have)
- Можливість примусового завершення (відміни/cancel) повислих задач.
- Передача результатів від Клима прямо у граф (виклик MCP-інструменту бази даних збоку Клима).

## 7. Технічна Архітектура
### Модель Даних (Task State)
Зберігання стану задач у пам'яті сервера `llm-provider-mcp` (наприклад, словник `Dict[task_id, TaskState]`), де `TaskState` містить статус, зібрані логи (або буфер логів) та фінальний результат генерації.
### Компоненти Системи
1. **MCP Server Endpoint:** Розширення FastMCP сервера `src/server.py` новими інструментами (`start_async_task`, `check_task_status`).
2. **Task Manager:** Логіка для керування пулом запущених фонових асинхронних викликів та збором логів.
3. **MCP Client Loop:** Логіка підключення Клима до основного сервера (SSE), яку ми переносимо з `test_client.py` і масштабуємо для використання всередині агента.
### Інтеграції (External APIs)
- `grynya-mcp-server` (http://grynya-mcp-server:8000/sse)
- LLM API (Gemini/OpenAI)

## 8. Нефункціональні Вимоги
- **Стабільність (Надійність):** Якщо одна задача зависла або впала з помилкою (наприклад, через Event Loop conflict або таймаут Gemini API), це не повинно "вбивати" сам головний `llm-provider-mcp` сервер.

## 9. Що "Поза рамками" (Out of Scope)
- Реалізація повноцінної розподіленої черги завдань (Celery, RabbitMQ) - тримаємо все максимально просто в рамках `asyncio` пулу.
- Постійне зберігання логів задач після рестарту Docker-контейнера `llm-provider-mcp` (поки тримаємо `in-memory`).

## 10. Відкриті питання для опрацювання розробниками
- Як найкраще обробляти контекст Event Loop при відкритті MCP-сесії зсередини іншої MCP-екзекуції (у FastMCP). Знадобиться правильне застосування `asyncio.create_task` та context vars.
